import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
import math
from utils import img_to_base64
import streamlit as st
from utils import load_css

load_css()

# ============================================================
# PAGE CONFIG
# ============================================================
st.set_page_config(
    page_title="NEXUS AI | AI Decision Engine",
    page_icon="ğŸ§©",
    layout="wide"
)

# ============================================================
# MULTI-LANGUAGE (extended with academic concept text)
# ============================================================
LANGS = {
    "English": {
        "title": "ğŸ§© AI Decision Engine",
        "subtitle": "Climate-driven prediction â€¢ Sensor confirmation â€¢ Decision support",
        "controls": "âš™ï¸ Controls",
        "date": "ğŸ“… Date",
        "risk_level": "ğŸ”¥ Risk level",
        "map_settings": "ğŸ—ºï¸ Map Settings",
        "view_mode": "View mode",
        "risk_thr": "Risk threshold",
        "radius": "Cluster radius (km)",
        "min_pts": "Min points",
        "tabs": ["ğŸ—ºï¸ Map", "ğŸ§  Decision Summary",  "ğŸ›ï¸ States", "ğŸ§ª Scenario", "âš–ï¸ Compare"],
        "scenario_inactive": "ğŸŸ¡ Scenario inactive â€” run a scenario to enable comparison",
        "scenario_active": "ğŸŸ¢ Scenario active â€” comparison enabled",
        "no_sensors": "No sensor data available.",
        "sensor_map_title": "ğŸ—ºï¸ Active Birdhouse Nodes",
        "sensor_map_caption": "Only nodes with meaningful local signals (sensor_score > threshold) are highlighted.",
        "forecast_title": "ğŸ”® Forecast Horizon",
        "forecast_caption": "A simple, explainable forecast indicator based on recent trend + assumptions.",
        "proximity_title": "ğŸš’ Proximity",
        "proximity_caption": "Operational context: distance & estimated response time to nearest fire station.",
        "alerts_title": "ğŸ”” Alerts",
        "alerts_caption": "Actionable alerts derived from climate trend + sensors + fusion.",
        "subscribe": "Subscribe to Alerts",
        "subscribe_hint": "Demo: stores your preference in session_state (no emails sent).",
        "on": "ON",
        "off": "OFF",
        "fusion": "Fusion Score",
        "final_level": "ğŸ”¥ FINAL LEVEL",
        "kpi_cells": "Grid cells",
        "kpi_hi": "High / Extreme",
        "kpi_avg": "Avg risk score",
        "kpi_date": "Date",
        "legend": "ğŸ¨ Risk Legend",
        "delta_legend": "ğŸ¨ Î” Risk Legend",
        "compare_hint": "No scenario executed yet. Go to Scenario tab and click Run Scenario.",
        "run_scenario": "Run Scenario",
        "run": "Run",
        "scenario_title": "ğŸ§ª What-If Analysis (Scenario Simulator)",
        "scenario_text": "Simulate what-if climate scenarios and assess their impact on wildfire risk.",
        "map_title": "ğŸ—ºï¸ Spatial Wildfire Risk",
        "state_title": "ğŸ›ï¸ Risk by State",
        "decision_title": "ğŸ§  Final Decision & Interpretation",
        "auto_explain": "ğŸ§  Auto Explanation",
        "sensor_timeline": "â±ï¸ Sensor Risk Timeline",
        "trend_title": "â±ï¸ Trend (last days)",
        "trend_empty": "Trend history will appear after multiple days are available.",
        "dir": "ltr",

        # NEW: Academic / concept text (Decision Engine storyline)
        "concept_block_title": "Concept Overview",
        "concept_block_text": (
            "The AI Decision Engine is the operational layer that converts heterogeneous evidence into an actionable wildfire "
            "risk decision. It aggregates (i) **climate-driven spatial risk** from gridded datasets, (ii) **ground-truth "
            "confirmation** from Birdhouse sensor nodes, and (iii) **decision support context** such as trend, hotspots, and "
            "response proximity. The result is a transparent decision pipeline: **observe â†’ fuse â†’ interpret â†’ act**."
        ),
        "map_concept_title": "Why the map exists",
        "map_concept_text": (
            "The spatial map provides situational awareness: it shows where risk is concentrated, how it is distributed across "
            "the territory, and which locations exceed operational thresholds. This enables prioritization of surveillance and "
            "resource allocation."
        ),
        "summary_concept_title": "How the final decision is formed",
        "summary_concept_text": (
            "The final level is derived from a **fusion score** that combines the climate signal (model-based risk) with the "
            "strongest available sensor confirmation (local evidence). This design reduces false alarms and improves trust: "
            "when climate risk is elevated but sensors are quiet, escalation is conservative; when both agree, the system "
            "escalates decisively."
        ),
        "why_sensor_map_title": "Why the Birdhouse map and table are here",
        "why_sensor_map_text": (
            "The Birdhouse map and the accompanying table provide traceable ground-truth evidence. They identify which nodes "
            "contribute meaningful signals, where they are located, and what their measured indicators are (e.g., PM2.5, RH, "
            "temperature). This supports auditability and operational decisions such as dispatching field checks."
        ),
        "forecast_explain_title": "What the forecast indicates",
        "forecast_explain_text": (
            "The forecast is an explainable indicator derived from recent-day risk evolution. It does not replace the core "
            "model; instead, it communicates whether conditions are *increasing*, *decreasing*, or *stable* within the selected "
            "horizon, helping planners anticipate near-term escalation."
        ),
        "proximity_explain_title": "Why proximity is included",
        "proximity_explain_text": (
            "Proximity adds an operational constraint: the same risk level can have different implications depending on "
            "expected response time. By estimating distance and response latency to nearby fire stations, the engine supports "
            "readiness and resource staging."
        ),
        "alerts_explain_title": "Why alerts are generated",
        "alerts_explain_text": (
            "Alerts translate analytics into actions. They summarize the most important escalations derived from state trends, "
            "sensor anomalies, and fusion thresholds, enabling a short, decision-ready list rather than raw telemetry."
        ),
    },
    "Deutsch": {
        "title": "ğŸ§© KI-Entscheidungsmodul",
        "subtitle": "Klima-Prognose â€¢ Sensor-BestÃ¤tigung â€¢ EntscheidungsunterstÃ¼tzung",
        "controls": "âš™ï¸ Steuerung",
        "date": "ğŸ“… Datum",
        "risk_level": "ğŸ”¥ Risikostufe",
        "map_settings": "ğŸ—ºï¸ Karten-Einstellungen",
        "view_mode": "Ansicht",
        "risk_thr": "Risikoschwelle",
        "radius": "Cluster-Radius (km)",
        "min_pts": "Min Punkte",
        "tabs": ["ğŸ—ºï¸ Karte", "ğŸ§  EntscheidungsÃ¼bersicht", "ğŸ›ï¸ BundeslÃ¤nder", "ğŸ§ª Szenario", "âš–ï¸ Vergleich"],
        "scenario_inactive": "ğŸŸ¡ Szenario inaktiv â€” fÃ¼hre ein Szenario aus, um den Vergleich zu aktivieren",
        "scenario_active": "ğŸŸ¢ Szenario aktiv â€” Vergleich aktiviert",
        "no_sensors": "Keine Sensordaten verfÃ¼gbar.",
        "sensor_map_title": "ğŸ—ºï¸ Aktive Birdhouse-Knoten",
        "sensor_map_caption": "Nur Knoten mit relevanten lokalen Signalen (sensor_score > Schwelle) werden markiert.",
        "forecast_title": "ğŸ”® Prognose-Horizont",
        "forecast_caption": "Ein einfacher, erklÃ¤rbarer Indikator basierend auf Trend + Annahmen.",
        "proximity_title": "ğŸš’ NÃ¤he (Einsatzkontext)",
        "proximity_caption": "Operativ: Entfernung & geschÃ¤tzte Anfahrtszeit zur nÃ¤chsten Feuerwehr.",
        "alerts_title": "ğŸ”” Warnungen",
        "alerts_caption": "Handlungsrelevante Warnungen aus Klima-Trend + Sensoren + Fusion.",
        "subscribe": "Warnungen abonnieren",
        "subscribe_hint": "Demo: Speichert nur die Auswahl in session_state (keine Emails).",
        "on": "AN",
        "off": "AUS",
        "fusion": "Fusions-Score",
        "final_level": "ğŸ”¥ ENDSTUFE",
        "kpi_cells": "Rasterzellen",
        "kpi_hi": "Hoch / Extrem",
        "kpi_avg": "Ã˜ Risikoscore",
        "kpi_date": "Datum",
        "legend": "ğŸ¨ Legende",
        "delta_legend": "ğŸ¨ Î”-Risiko Legende",
        "compare_hint": "Noch kein Szenario. Gehe zum Szenario-Tab und starte es.",
        "run_scenario": "Szenario ausfÃ¼hren",
        "run": "Start",
        "scenario_title": "ğŸ§ª Was-wÃ¤re-wenn Analyse (Szenario)",
        "scenario_text": "Simuliere Klima-Szenarien und bewerte den Einfluss auf das Waldbrandrisiko.",
        "map_title": "ğŸ—ºï¸ RÃ¤umliches Waldbrandrisiko",
        "state_title": "ğŸ›ï¸ Risiko nach Bundesland",
        "decision_title": "ğŸ§  Entscheidung & Interpretation",
        "auto_explain": "ğŸ§  Auto-ErklÃ¤rung",
        "sensor_timeline": "â±ï¸ Sensor-Risiko-Zeitverlauf",
        "trend_title": "â±ï¸ Trend (letzte Tage)",
        "trend_empty": "Trend erscheint, sobald mehrere Tage verfÃ¼gbar sind.",
        "dir": "ltr",

        # NEW: Academic / concept text (DE)
        "concept_block_title": "KonzeptÃ¼bersicht",
        "concept_block_text": (
            "Das KI-Entscheidungsmodul ist die operative Schicht, die heterogene Evidenz in eine handlungsfÃ¤hige "
            "Waldbrand-Entscheidung Ã¼berfÃ¼hrt. Es bÃ¼ndelt (i) **klimabasierte rÃ¤umliche Risiken** aus Rasterdaten, "
            "(ii) **Ground-Truth-BestÃ¤tigung** durch Birdhouse-Sensorknoten und (iii) **EntscheidungsunterstÃ¼tzung** "
            "wie Trend, Hotspots und EinsatznÃ¤he. Daraus entsteht eine transparente Pipeline: **beobachten â†’ fusionieren "
            "â†’ interpretieren â†’ handeln**."
        ),
        "map_concept_title": "Warum es eine Karte gibt",
        "map_concept_text": (
            "Die rÃ¤umliche Karte liefert Lagebild und Priorisierung: Sie zeigt, wo Risiko konzentriert ist, wie es sich "
            "verteilt und welche Bereiche operative Schwellen Ã¼berschreiten. Das unterstÃ¼tzt Monitoring und Einsatzplanung."
        ),
        "summary_concept_title": "Wie die Endstufe entsteht",
        "summary_concept_text": (
            "Die Endstufe basiert auf einem **Fusions-Score**, der das Klimasignal (modellbasiert) mit der stÃ¤rksten "
            "SensorbestÃ¤tigung (lokale Evidenz) kombiniert. Dieses Design reduziert Fehlalarme und erhÃ¶ht Vertrauen: "
            "bei hohem Klimarisiko ohne lokale BestÃ¤tigung bleibt die Eskalation konservativ; bei Ãœbereinstimmung erfolgt "
            "eine klare Eskalation."
        ),
        "why_sensor_map_title": "Warum Birdhouse-Karte und Tabelle hier sind",
        "why_sensor_map_text": (
            "Birdhouse-Karte und Tabelle liefern nachvollziehbare Ground-Truth-Evidenz. Sie zeigen, welche Knoten relevante "
            "Signale beitragen, wo sie liegen und welche Indikatoren gemessen werden (z. B. PM2.5, RH, Temperatur). "
            "Das unterstÃ¼tzt Auditierbarkeit und operative Entscheidungen (z. B. Vor-Ort-Checks)."
        ),
        "forecast_explain_title": "Was die Prognose aussagt",
        "forecast_explain_text": (
            "Die Prognose ist ein erklÃ¤rbarer Indikator aus der Entwicklung der letzten Tage. Sie ersetzt nicht das Modell, "
            "sondern kommuniziert, ob Bedingungen innerhalb des gewÃ¤hlten Horizonts *steigen*, *fallen* oder *stabil* sind."
        ),
        "proximity_explain_title": "Warum NÃ¤he berÃ¼cksichtigt wird",
        "proximity_explain_text": (
            "NÃ¤he ergÃ¤nzt operative Rahmenbedingungen: Gleiches Risiko kann je nach erwarteter Anfahrtszeit unterschiedliche "
            "Folgen haben. Die Distanz- und ETA-SchÃ¤tzung unterstÃ¼tzt Bereitschaft und Ressourcen-Vorpositionierung."
        ),
        "alerts_explain_title": "Warum Warnungen generiert werden",
        "alerts_explain_text": (
            "Warnungen Ã¼bersetzen Analytik in Handlung. Sie verdichten Eskalationen aus Trend, Sensoranomalien und "
            "Fusionsschwellen zu einer kurzen, entscheidungsreifen Liste."
        ),
    },
    "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": {
        "title": "ğŸ§© Ù…Ø­Ø±Ùƒ Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ø°ÙƒÙŠ",
        "subtitle": "ØªÙ†Ø¨Ø¤ Ù…Ù†Ø§Ø®ÙŠ â€¢ ØªØ£ÙƒÙŠØ¯ Ø­Ø³Ø§Ø³Ø§Øª â€¢ Ø¯Ø¹Ù… Ù‚Ø±Ø§Ø±",
        "controls": "âš™ï¸ Ø§Ù„ØªØ­ÙƒÙ…",
        "date": "ğŸ“… Ø§Ù„ØªØ§Ø±ÙŠØ®",
        "risk_level": "ğŸ”¥ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø®Ø·Ø±",
        "map_settings": "ğŸ—ºï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø®Ø±ÙŠØ·Ø©",
        "view_mode": "ÙˆØ¶Ø¹ Ø§Ù„Ø¹Ø±Ø¶",
        "risk_thr": "Ø¹ØªØ¨Ø© Ø§Ù„Ø®Ø·Ø±",
        "radius": "Ù†ØµÙ Ù‚Ø·Ø± Ø§Ù„ØªØ¬Ù…Ø¹ (ÙƒÙ…)",
        "min_pts": "Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„Ù†Ù‚Ø§Ø·",
        "tabs": ["ğŸ—ºï¸ Ø§Ù„Ø®Ø±ÙŠØ·Ø©", "ğŸ§  Ù…Ù„Ø®Øµ Ø§Ù„Ù‚Ø±Ø§Ø±", "ğŸ›ï¸ Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª", "ğŸ§ª Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ", "âš–ï¸ Ù…Ù‚Ø§Ø±Ù†Ø©"],
        "scenario_inactive": "ğŸŸ¡ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ ØºÙŠØ± Ù…ÙØ¹Ù‘Ù„ â€” Ø´ØºÙ‘Ù„ Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ù„ØªÙØ¹ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©",
        "scenario_active": "ğŸŸ¢ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ù…ÙØ¹Ù‘Ù„ â€” Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø¬Ø§Ù‡Ø²Ø©",
        "no_sensors": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø§Ø³Ø§Øª.",
        "sensor_map_title": "ğŸ—ºï¸ Ø¹Ù‚Ø¯ Birdhouse Ø§Ù„Ù†Ø´Ø·Ø©",
        "sensor_map_caption": "Ù†ÙØ¸Ù‡Ø± ÙÙ‚Ø· Ø§Ù„Ø¹Ù‚Ø¯ Ø°Ø§Øª Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© (sensor_score > Ø§Ù„Ø¹ØªØ¨Ø©).",
        "forecast_title": "ğŸ”® Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ",
        "forecast_caption": "Ù…Ø¤Ø´Ø± ØªÙ†Ø¨Ø¤ Ø¨Ø³ÙŠØ· ÙˆØ´ÙØ§Ù ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø£Ø®ÙŠØ± + Ø§ÙØªØ±Ø§Ø¶Ø§Øª.",
        "proximity_title": "ğŸš’ Ø§Ù„Ù‚Ø±Ø¨ Ù…Ù† Ù…Ø­Ø·Ø© Ø§Ù„Ø¥Ø·ÙØ§Ø¡",
        "proximity_caption": "Ø³ÙŠØ§Ù‚ ØªØ´ØºÙŠÙ„ÙŠ: Ø§Ù„Ù…Ø³Ø§ÙØ© ÙˆØ²Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ù„Ø£Ù‚Ø±Ø¨ Ù…Ø­Ø·Ø©.",
        "alerts_title": "ğŸ”” Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª",
        "alerts_caption": "ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø¹Ù…Ù„ÙŠØ© Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ù…Ù†Ø§Ø®ÙŠ + Ø§Ù„Ø­Ø³Ø§Ø³Ø§Øª + Ø§Ù„Ø¯Ù…Ø¬.",
        "subscribe": "Ø§Ø´ØªØ±Ø§Ùƒ Ø¨Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª",
        "subscribe_hint": "Ø¹Ø±Ø¶ ØªØ¬Ø±ÙŠØ¨ÙŠ: ÙŠØ®Ø²Ù† Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± ÙÙ‚Ø· (Ø¨Ø¯ÙˆÙ† Ø¥Ø±Ø³Ø§Ù„ Ø¨Ø±ÙŠØ¯).",
        "on": "ØªØ´ØºÙŠÙ„",
        "off": "Ø¥ÙŠÙ‚Ø§Ù",
        "fusion": "Ø¯Ø±Ø¬Ø© Ø§Ù„Ø¯Ù…Ø¬",
        "final_level": "ğŸ”¥ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ",
        "kpi_cells": "Ø¹Ø¯Ø¯ Ø§Ù„Ø®Ù„Ø§ÙŠØ§",
        "kpi_hi": "Ø¹Ø§Ù„ÙŠ / Ø´Ø¯ÙŠØ¯ Ø¬Ø¯Ù‹Ø§",
        "kpi_avg": "Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®Ø·Ø±",
        "kpi_date": "Ø§Ù„ØªØ§Ø±ÙŠØ®",
        "legend": "ğŸ¨ Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø£Ù„ÙˆØ§Ù†",
        "delta_legend": "ğŸ¨ Ø¯Ù„ÙŠÙ„ ÙØ±Ù‚ Ø§Ù„Ø®Ø·Ø± Î”",
        "compare_hint": "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø¨Ø¹Ø¯. Ø§Ø°Ù‡Ø¨ Ù„ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ ÙˆØ´ØºÙ‘Ù„Ù‡.",
        "run_scenario": "ØªØ´ØºÙŠÙ„ Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ",
        "run": "ØªØ´ØºÙŠÙ„",
        "scenario_title": "ğŸ§ª ØªØ­Ù„ÙŠÙ„ Ù…Ø§Ø°Ø§ Ù„ÙˆØŸ",
        "scenario_text": "Ø­Ø§ÙƒÙŠ Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª Ù…Ù†Ø§Ø®ÙŠØ© ÙˆØ§ÙØ­Øµ ØªØ£Ø«ÙŠØ±Ù‡Ø§ Ø¹Ù„Ù‰ Ø®Ø·Ø± Ø§Ù„Ø­Ø±ÙŠÙ‚.",
        "map_title": "ğŸ—ºï¸ Ø§Ù„Ø®Ø·Ø± Ø§Ù„Ù…ÙƒØ§Ù†ÙŠ",
        "state_title": "ğŸ›ï¸ Ø§Ù„Ø®Ø·Ø± Ø­Ø³Ø¨ Ø§Ù„ÙˆÙ„Ø§ÙŠØ©",
        "decision_title": "ğŸ§  Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙˆØ§Ù„ØªÙØ³ÙŠØ±",
        "auto_explain": "ğŸ§  ØªÙØ³ÙŠØ± ØªÙ„Ù‚Ø§Ø¦ÙŠ",
        "sensor_timeline": "â±ï¸ Ø®Ø· Ø²Ù…Ù†ÙŠ Ù„Ø®Ø·Ø± Ø§Ù„Ø­Ø³Ø§Ø³Ø§Øª",
        "trend_title": "â±ï¸ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ (Ø¢Ø®Ø± Ø£ÙŠØ§Ù…)",
        "trend_empty": "Ø³ÙŠØ¸Ù‡Ø± Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø¹Ù†Ø¯ ØªÙˆÙØ± Ø£ÙƒØ«Ø± Ù…Ù† ÙŠÙˆÙ….",
        "dir": "rtl",

        # NEW: Academic / concept text (AR)
        "concept_block_title": "Ù†Ø¸Ø±Ø© Ù…ÙØ§Ù‡ÙŠÙ…ÙŠØ©",
        "concept_block_text": (
            "Ù…Ø­Ø±Ùƒ Ø§Ù„Ù‚Ø±Ø§Ø± Ù‡Ùˆ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ÙŠØ© Ø§Ù„ØªÙŠ ØªØ­ÙˆÙ„ Ø§Ù„Ø£Ø¯Ù„Ø© Ø§Ù„Ù…ØªÙ†ÙˆØ¹Ø© Ø¥Ù„Ù‰ Ù‚Ø±Ø§Ø± Ø¹Ù…Ù„ÙŠ Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ø­Ø±Ø§Ø¦Ù‚. ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† "
            "(1) **Ø®Ø·Ø± Ù…ÙƒØ§Ù†ÙŠ Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†Ø§Ø®** Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ø¨ÙƒÙŠØ©ØŒ (2) **ØªØ£ÙƒÙŠØ¯ Ù…ÙŠØ¯Ø§Ù†ÙŠ (Ground Truth)** Ù…Ù† Ø¹Ù‚Ø¯ BirdhouseØŒ "
            "Ùˆ(3) **Ø¯Ø¹Ù… Ù‚Ø±Ø§Ø±** Ù…Ø«Ù„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ ÙˆØ§Ù„Ø¨Ø¤Ø± Ø§Ù„Ø³Ø§Ø®Ù†Ø© ÙˆÙ‚Ø±Ø¨ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©. Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø®Ø· Ù‚Ø±Ø§Ø± Ø´ÙØ§Ù: "
            "**Ù†Ø±ØµØ¯ â†’ Ù†Ø¯Ù…Ø¬ â†’ Ù†ÙØ³Ù‘Ø± â†’ Ù†ØªØ­Ø±Ùƒ**."
        ),
        "map_concept_title": "Ù„Ù…Ø§Ø°Ø§ Ù†Ø¹Ø±Ø¶ Ø®Ø±ÙŠØ·Ø©",
        "map_concept_text": (
            "Ø§Ù„Ø®Ø±ÙŠØ·Ø© ØªÙ‚Ø¯Ù… ÙˆØ¹ÙŠÙ‹Ø§ Ù…ÙƒØ§Ù†ÙŠÙ‹Ø§ ÙˆØ§Ø¶Ø­Ù‹Ø§: Ø£ÙŠÙ† ÙŠØªØ±ÙƒØ² Ø§Ù„Ø®Ø·Ø± ÙˆÙƒÙŠÙ ÙŠØªÙˆØ²Ø¹ØŒ ÙˆØ£ÙŠ Ù…Ù†Ø§Ø·Ù‚ ØªØªØ¬Ø§ÙˆØ² Ø§Ù„Ø¹ØªØ¨Ø§Øª Ø§Ù„ØªØ´ØºÙŠÙ„ÙŠØ©. "
            "Ù‡Ø°Ø§ ÙŠØ³Ø§Ø¹Ø¯ Ø¹Ù„Ù‰ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª Ù„Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© ÙˆØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯."
        ),
        "summary_concept_title": "ÙƒÙŠÙ Ù†Ù†ØªØ¬ Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ",
        "summary_concept_text": (
            "Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ **Ø¯Ø±Ø¬Ø© Ø¯Ù…Ø¬** ØªØ¬Ù…Ø¹ Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ù…Ù†Ø§Ø® (Ø®Ø·Ø± Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬) Ù…Ø¹ Ø£Ù‚ÙˆÙ‰ ØªØ£ÙƒÙŠØ¯ Ù…Ù† Ø§Ù„Ø­Ø³Ø§Ø³Ø§Øª "
            "(Ø¯Ù„ÙŠÙ„ Ù…Ø­Ù„ÙŠ). Ù‡Ø°Ø§ ÙŠÙ‚Ù„Ù„ Ø§Ù„Ø¥Ù†Ø°Ø§Ø±Ø§Øª Ø§Ù„ÙƒØ§Ø°Ø¨Ø© ÙˆÙŠØ±ÙØ¹ Ø§Ù„Ø«Ù‚Ø©: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø®Ø·Ø± Ø§Ù„Ù…Ù†Ø§Ø®ÙŠ Ù…Ø±ØªÙØ¹Ù‹Ø§ Ù„ÙƒÙ† Ø§Ù„Ø­Ø³Ø§Ø³Ø§Øª Ù‡Ø§Ø¯Ø¦Ø© "
            "ØªØ¨Ù‚Ù‰ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ø­Ø§ÙØ¸Ø©Ø› ÙˆØ¥Ø°Ø§ Ø§ØªÙÙ‚Øª Ø§Ù„Ø¥Ø´Ø§Ø±ØªØ§Ù† ÙŠØµÙŠØ± Ø§Ù„ØªØµØ¹ÙŠØ¯ Ø­Ø§Ø³Ù…Ù‹Ø§."
        ),
        "why_sensor_map_title": "Ù„Ù…Ø§Ø°Ø§ Ø®Ø±ÙŠØ·Ø© ÙˆØ¬Ø¯ÙˆÙ„ Birdhouse Ù‡Ù†Ø§",
        "why_sensor_map_text": (
            "Ø®Ø±ÙŠØ·Ø© ÙˆØ¬Ø¯ÙˆÙ„ Birdhouse ÙŠÙ‚Ø¯Ù…Ø§Ù† Ø¯Ù„ÙŠÙ„Ù‹Ø§ Ù…ÙŠØ¯Ø§Ù†ÙŠÙ‹Ø§ Ù‚Ø§Ø¨Ù„Ù‹Ø§ Ù„Ù„ØªØªØ¨Ø¹: Ø£ÙŠ Ø¹Ù‚Ø¯Ø© Ø³Ø§Ù‡Ù…Øª Ø¨Ø¥Ø´Ø§Ø±Ø© Ù…Ù‡Ù…Ø©ØŒ Ø£ÙŠÙ† Ù…ÙˆÙ‚Ø¹Ù‡Ø§ØŒ "
            "ÙˆÙ…Ø§ Ù‡ÙŠ Ø§Ù„Ù‚ÙŠØ§Ø³Ø§Øª (Ù…Ø«Ù„ PM2.5 ÙˆØ§Ù„Ø±Ø·ÙˆØ¨Ø© ÙˆØ§Ù„Ø­Ø±Ø§Ø±Ø©). Ù‡Ø°Ø§ Ù…Ù‡Ù… Ù„Ù„ØªØ¯Ù‚ÙŠÙ‚ ÙˆÙ„Ø§ØªØ®Ø§Ø° Ù‚Ø±Ø§Ø± Ø¥Ø±Ø³Ø§Ù„ ÙØ±Ù‚ ÙØ­Øµ."
        ),
        "forecast_explain_title": "Ù…Ø§Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤",
        "forecast_explain_text": (
            "Ø§Ù„ØªÙ†Ø¨Ø¤ Ù‡Ù†Ø§ Ù…Ø¤Ø´Ø± Ø¨Ø³ÙŠØ· ÙˆØ´ÙØ§Ù Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ ØªØºÙŠØ± Ø§Ù„Ø®Ø·Ø± Ø®Ù„Ø§Ù„ Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ø£Ø®ÙŠØ±Ø©. Ù„Ø§ ÙŠØ³ØªØ¨Ø¯Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ Ù„ÙƒÙ†Ù‡ ÙŠÙˆØ¶Ø­ "
            "Ù‡Ù„ Ø§Ù„Ø®Ø·Ø± *ÙŠØ±ØªÙØ¹* Ø£Ùˆ *ÙŠÙ†Ø®ÙØ¶* Ø£Ùˆ *Ù…Ø³ØªÙ‚Ø±* Ø®Ù„Ø§Ù„ Ø§Ù„Ø£ÙÙ‚ Ø§Ù„Ù…Ø®ØªØ§Ø±."
        ),
        "proximity_explain_title": "Ù„Ù…Ø§Ø°Ø§ Ù†Ø¶ÙŠÙ Ø§Ù„Ù‚Ø±Ø¨",
        "proximity_explain_text": (
            "Ø§Ù„Ù‚Ø±Ø¨ ÙŠØ¶ÙŠÙ Ø¨ÙØ¹Ø¯Ù‹Ø§ ØªØ´ØºÙŠÙ„ÙŠÙ‹Ø§: Ù†ÙØ³ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø®Ø·Ø± Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø£Ø®Ø·Ø± ÙÙŠ Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø¨Ø¹ÙŠØ¯Ø© Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©. ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ù…Ø³Ø§ÙØ© ÙˆØ²Ù…Ù† "
            "Ø§Ù„ÙˆØµÙˆÙ„ ÙŠØ³Ø§Ø¹Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ø§Ù‡Ø²ÙŠØ© ÙˆØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ù‚Ø¨Ù„ Ø§Ù„ØªØµØ¹ÙŠØ¯."
        ),
        "alerts_explain_title": "Ù„Ù…Ø§Ø°Ø§ Ù†ÙˆÙ„Ø¯ ØªÙ†Ø¨ÙŠÙ‡Ø§Øª",
        "alerts_explain_text": (
            "Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª ØªØ­ÙˆÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¥Ù„Ù‰ Ø£ÙØ¹Ø§Ù„. Ù‡ÙŠ ØªÙ„Ø®Øµ Ø£Ù‡Ù… Ø§Ù„ØªØµØ¹ÙŠØ¯Ø§Øª Ø§Ù„Ù†Ø§ØªØ¬Ø© Ø¹Ù† Ø§ØªØ¬Ø§Ù‡ Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª ÙˆØ¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø§Øª ÙˆØ¹ØªØ¨Ø§Øª "
            "Ø§Ù„Ø¯Ù…Ø¬ØŒ Ø¨Ø¯Ù„ ØªØ±Ùƒ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£Ù…Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ø®Ø§Ù… ÙƒØ«ÙŠØ±Ø©."
        ),
    }
}

# ============================================================
# SIDEBAR (Unified)
# ============================================================
with st.sidebar:
    lang = st.selectbox("ğŸŒ Language", list(LANGS.keys()))
    T = LANGS[lang]

    st.divider()
    st.markdown("### ğŸ§­ Navigation")
    cnav1, cnav2 = st.columns(2)
    with cnav1:
        if st.button("ğŸ§  AI Hub", use_container_width=True):
            try:
                st.switch_page("pages/1_AI_Hub.py")
            except Exception:
                st.warning("AI Hub page path not found.")
    with cnav2:
        if st.button("ğŸŒ² Hardware", use_container_width=True):
            try:
                st.switch_page("pages/2_Hardware.py")
            except Exception:
                st.warning("Hardware page path not found.")

    st.divider()
    st.markdown(f"### {T['controls']}")

# ============================================================
# STYLING (Unified Dark Premium)
# ============================================================
st.markdown(f"""
<style>
/* ====== GLOBAL ====== */
.main {{
  direction: {T['dir']};
  text-align: {'right' if T['dir']=='rtl' else 'left'};
  background-color: #EAF4EC; /* ØªØºÙŠÙŠØ± Ø§Ù„Ø®Ù„ÙÙŠØ© Ù„ØªÙ†Ø§Ø³Ø¨ Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ø¹Ø§Ù… */
}}

/* ====== SECTION TITLE (Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø£Ù‚Ø³Ø§Ù…) ====== */
.section-title {{
  border: 1px solid #FF8C00;
  background: rgba(255, 140, 0, 0.1);
  border-radius: 14px;
  padding: .55rem .9rem;
  margin: 1rem 0 .75rem 0;
  font-size: 1.15rem;
  font-weight: 800;
  color: #000000; /* ØªØºÙŠÙŠØ± Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ù„Ù„Ø£Ø³ÙˆØ¯ */
  display: inline-block;
}}

/* ====== CARDS (Ø£Ù„ÙˆØ§Ù†Ùƒ Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù…Ø¹ Ù†ØµÙˆØµ Ø³ÙˆØ¯Ø§Ø¡) ====== */
.status-card {{
  background: rgba(251, 146, 60, 0.15); /* Ù„ÙˆÙ†Ùƒ Ø§Ù„Ø£ØµÙ„ÙŠ */
  backdrop-filter: blur(12px);
  padding: 18px 18px;
  border-radius: 16px;
  border: 1px solid #f97316;
  margin: 12px 0;
  color: #000000 !important;
}}

.kpi-wrap {{
  background: rgba(234, 88, 12, 0.1); /* Ù„ÙˆÙ†Ùƒ Ø§Ù„Ø£ØµÙ„ÙŠ */
  border: 1px solid rgba(251, 146, 60, 0.4);
  border-radius: 16px;
  padding: 12px 14px;
  color: #000000 !important;
}}

/* Ø¶Ù…Ø§Ù† Ø£Ù† ÙƒÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø¯Ø§Ø®Ù„ Ø§Ù„ÙƒØ±ÙˆØª Ø³ÙˆØ¯Ø§Ø¡ */
.status-card *, .kpi-wrap *, .legend-box * {{
  color: #000000 !important;
}}

.small-muted {{
  color: #475569; /* Ø¬Ø¹Ù„Ù‡Ø§ Ø£ØºÙ…Ù‚ Ù‚Ù„ÙŠÙ„Ø§Ù‹ Ù„ØªØ¸Ù‡Ø± ÙÙˆÙ‚ Ø§Ù„Ø®Ù„ÙÙŠØ© Ø§Ù„ÙØ§ØªØ­Ø© */
  font-size: 0.92rem;
}}

/* ====== SIDEBAR (Ø£Ø®Ø¶Ø± ÙˆÙƒØªØ§Ø¨Ø© Ø¨ÙŠØ¶Ø§Ø¡ ØµØ±ÙŠØ­Ø©) ====== */
section[data-testid="stSidebar"] {{
  background-color: #0F3D2E !important;
  border-right: 4px solid #FF8C00;
}}

/* Ø¥Ø¬Ø¨Ø§Ø± ÙƒÙ„ Ù†ØµÙˆØµ Ø§Ù„Ø³Ø§ÙŠØ¯ Ø¨Ø§Ø± Ø¹Ù„Ù‰ Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ø£Ø¨ÙŠØ¶ */
section[data-testid="stSidebar"] *, 
section[data-testid="stSidebar"] [data-testid="stMarkdownContainer"] p,
section[data-testid="stSidebar"] label,
section[data-testid="stSidebar"] span {{
  color: #FFFFFF !important;
  font-weight: 600 !important;
}}

/* ØªÙ†Ø³ÙŠÙ‚ Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø³Ø§ÙŠØ¯ Ø¨Ø§Ø± */
section[data-testid="stSidebar"] input,
section[data-testid="stSidebar"] textarea {{
  color: #000000 !important;
  background-color: #ffffff !important;
  border-radius: 8px;
}}

/* Ù…Ø³ØªØ·ÙŠÙ„ Ø§Ù„Ù„ØºØ§Øª ÙˆØ§Ù„Ù€ Selectbox Ø¯Ø§Ø®Ù„ Ø§Ù„Ø³Ø§ÙŠØ¯ Ø¨Ø§Ø± */
section[data-testid="stSidebar"] div[data-baseweb="select"] > div {{
  background-color: #FF8C00 !important;
  border: none !important;
}}

section[data-testid="stSidebar"] div[data-baseweb="select"] span {{
  color: #000000 !important; /* Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø®ØªØ§Ø± Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø±Ø¨Ø¹ Ø£Ø³ÙˆØ¯ */
  font-weight: 800 !important;
}}

.legend-box {{
  background: rgba(251, 146, 60, 0.15); 
  backdrop-filter: blur(10px);
  border-radius: 14px;
  padding: .8rem 1rem;
  border: 1px solid #f97316;
  color: #000000;
}}

/* ====== LEGEND COLOR FIX ====== */
.legend-box span {{s
  font-weight: 900;
}} 


</style>
""", unsafe_allow_html=True)

def section(title: str):
    st.markdown(f'<div class="section-title">{title}</div>', unsafe_allow_html=True)

# ============================================================
# PATHS
# ============================================================
BASE_DIR = Path(__file__).resolve().parents[1]
PARQUET_PATH = BASE_DIR / "daily_risk.parquet"
STATES_PATH = BASE_DIR / "data" / "germany_states.geojson"
SENSOR_DATA_PATH = BASE_DIR / "data" / "sensor_readings.csv"

# ============================================================
# OPTIONAL IMPORTS (components) + FALLBACKS
# ============================================================
# --- MAPS (optional) ---
try:
    from nexus_ai.components.maps import render_point_risk_map, render_hex_risk_map
except Exception:
    render_point_risk_map = None
    render_hex_risk_map = None

# --- STATE RISK (optional) ---
try:
    from nexus_ai.components.state_risk import load_states, compute_state_risk, render_state_risk_map
except Exception:
    load_states = None
    compute_state_risk = None
    render_state_risk_map = None

# --- TREND (optional) ---
try:
    from nexus_ai.components.trend_analysis import compute_state_trend
except Exception:
    compute_state_trend = None

# --- ALERTS (optional) ---
try:
    from nexus_ai.components.alerts import generate_alerts
except Exception:
    generate_alerts = None

# --- AUTO EXPLAIN (optional) ---
try:
    from nexus_ai.components.auto_explain import generate_risk_explanation
except Exception:
    generate_risk_explanation = None

# --- SCENARIO (optional) ---
try:
    from nexus_ai.components.scenario_simulator import render_scenario_simulator
except Exception:
    render_scenario_simulator = None

# --- COMPARE (optional) ---
try:
    from nexus_ai.components.compare_scenario import render_compare_map
except Exception:
    render_compare_map = None

# --- SENSORS (optional) ---
try:
    from nexus_ai.components.sensor_nodes import load_sensor_data, render_sensor_nodes_map
except Exception:
    load_sensor_data = None
    render_sensor_nodes_map = None

try:
    from nexus_ai.components.sensor_alerts import generate_sensor_alerts
except Exception:
    generate_sensor_alerts = None

try:
    from nexus_ai.components.fusion_engine import compute_fusion_score, fusion_level
except Exception:
    compute_fusion_score = None
    fusion_level = None


# ============================================================
# FALLBACK UTILS
# ============================================================
def load_parquet_safe(path: Path) -> tuple[pd.DataFrame, str]:
    if not path.exists():
        st.error(f"Missing parquet file: {path}")
        return pd.DataFrame(), "date"
    df = pd.read_parquet(str(path))
    date_col = "date" if "date" in df.columns else ("time" if "time" in df.columns else None)
    if date_col is None:
        st.error("Parquet missing a date/time column (expected 'date' or 'time').")
        return pd.DataFrame(), "date"
    df[date_col] = pd.to_datetime(df[date_col], errors="coerce")
    df = df.dropna(subset=[date_col])
    if "risk_level" not in df.columns:
        df["risk_level"] = "unknown"
    if "risk_score" not in df.columns:
        st.error("Parquet missing 'risk_score' column.")
        return pd.DataFrame(), date_col
    return df, date_col

def compute_sensor_score_row(row) -> float:
    score = 0.0
    pm25 = float(row.get("pm25", 0) or 0)
    rh = float(row.get("rh", 100) or 100)
    temp = float(row.get("temp_c", 0) or 0)

    if pm25 > 50:
        score += 0.45
    if rh < 30:
        score += 0.35
    if temp > 30:
        score += 0.25
    return float(min(score, 1.0))

def simple_fusion_score(climate_risk_0_1: float, sensor_risk_0_1: float | None) -> float:
    # fallback fusion if fusion_engine missing
    if sensor_risk_0_1 is None:
        return float(np.clip(climate_risk_0_1, 0, 1))
    return float(np.clip(0.65 * climate_risk_0_1 + 0.35 * sensor_risk_0_1, 0, 1))

def simple_fusion_level(fusion_0_1: float) -> str:
    if fusion_0_1 >= 0.80:
        return "EXTREME"
    if fusion_0_1 >= 0.60:
        return "HIGH"
    if fusion_0_1 >= 0.30:
        return "MEDIUM"
    return "LOW"

def haversine_km(lat1, lon1, lat2, lon2) -> float:
    R = 6371.0
    p1 = math.radians(lat1); p2 = math.radians(lat2)
    d1 = math.radians(lat2 - lat1)
    d2 = math.radians(lon2 - lon1)
    a = math.sin(d1/2)**2 + math.cos(p1)*math.cos(p2)*math.sin(d2/2)**2
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
    return R * c

def trend_from_series(values: list[float]) -> str:
    # very simple direction for forecast indicator
    if len(values) < 3:
        return "stable"
    x = np.arange(len(values), dtype=float)
    y = np.array(values, dtype=float)
    # slope via polyfit
    slope = np.polyfit(x, y, 1)[0]
    if slope > 0.005:
        return "up"
    if slope < -0.005:
        return "down"
    return "stable"

# ============================================================
# HEADER
# ============================================================
st.title(T["title"])
st.markdown(f"<p class='small-muted'>{T['subtitle']}</p>", unsafe_allow_html=True)

# NEW: Academic concept overview (added, no design changes)
section(f"ğŸ“Œ {T['concept_block_title']}")
st.markdown("<div class='status-card'>", unsafe_allow_html=True)
st.markdown(T["concept_block_text"])
st.markdown("</div>", unsafe_allow_html=True)

st.divider()

# ============================================================
# LOAD DATA
# ============================================================
df, date_col = load_parquet_safe(PARQUET_PATH)
if df.empty:
    st.stop()

all_dates = sorted(df[date_col].dt.date.unique())
default_idx = max(0, len(all_dates) - 1)

# ============================================================
# SIDEBAR CONTROLS (Unified)
# ============================================================
with st.sidebar:
    selected_date = st.selectbox(T["date"], all_dates, index=default_idx)

    levels = ["all"] + sorted(df["risk_level"].astype(str).unique())
    selected_level = st.selectbox(T["risk_level"], levels)

    st.divider()
    st.markdown(f"### {T['map_settings']}")
    map_mode = st.radio(T["view_mode"], ["Points", "Hex"], horizontal=True)

    st.divider()
    score_threshold = st.slider(T["risk_thr"], 0.5, 0.95, 0.7, 0.05)
    eps_km = st.slider(T["radius"], 10, 80, 25, 5)
    min_samples = st.slider(T["min_pts"], 3, 30, 10, 1)

    st.divider()
    # Alerts subscription demo toggle
    if "subscribed_alerts" not in st.session_state:
        st.session_state.subscribed_alerts = False

    sub_label = f"ğŸ”” {T['subscribe']} ({T['on'] if st.session_state.subscribed_alerts else T['off']})"
    if st.button(sub_label, use_container_width=True):
        st.session_state.subscribed_alerts = not st.session_state.subscribed_alerts
        st.toast(T["subscribe_hint"])
        st.rerun()

# ============================================================
# FILTER DATA (day + level)
# ============================================================
df_day = df[df[date_col].dt.date == selected_date].copy()
if selected_level != "all":
    df_day = df_day[df_day["risk_level"].astype(str) == str(selected_level)].copy()

# yesterday
yesterday_df = None
idx = all_dates.index(selected_date)
if idx > 0:
    yday = all_dates[idx - 1]
    yesterday_df = df[df[date_col].dt.date == yday].copy()

# ============================================================
# KPIs (Unified)
# ============================================================
with st.container():
    st.markdown('<div class="kpi-wrap">', unsafe_allow_html=True)
    c1, c2, c3, c4 = st.columns(4)
    c1.metric(T["kpi_cells"], len(df_day))
    c2.metric(T["kpi_hi"], int((df_day["risk_level"].isin(["high", "extreme"])).sum()) if "risk_level" in df_day.columns else 0)
    c3.metric(T["kpi_avg"], round(float(df_day["risk_score"].mean()) if not df_day.empty else 0.0, 3))
    c4.metric(T["kpi_date"], str(selected_date))
    st.markdown("</div>", unsafe_allow_html=True)

st.divider()

# ============================================================
# SCENARIO STATUS INDICATOR
# ============================================================
scenario_risk = st.session_state.get("scenario_risk_score", None)
if scenario_risk is None:
    st.warning(T["scenario_inactive"])
else:
    st.success(T["scenario_active"])

# ============================================================
# STATES + TREND + ALERTS (if components exist)
# ============================================================
states_trend = None
state_alerts = []

if load_states and compute_state_risk and compute_state_trend:
    try:
        states_gdf = load_states(STATES_PATH)
        states_today = compute_state_risk(df_day, states_gdf)
        states_yday = compute_state_risk(yesterday_df, states_gdf) if yesterday_df is not None else None
        states_trend = compute_state_trend(states_today, states_yday)

        if generate_alerts:
            state_alerts = generate_alerts(states_trend, None)  # second arg kept as None (as your original)
        else:
            # fallback: simple alert summary
            top = states_trend.sort_values("mean_risk", ascending=False).head(3)
            state_alerts = [f"State escalation focus: {', '.join(top['NAME_1'].astype(str).tolist())}"]
    except Exception as e:
        state_alerts = [f"State trend failed: {e}"]
else:
    # fallback if state components missing
    state_alerts = ["State module unavailable (components/state_risk or trend_analysis not connected)."]

# ============================================================
# SENSORS
# ============================================================
df_sensors = pd.DataFrame()
sensor_alerts = []

if SENSOR_DATA_PATH.exists():
    try:
        if load_sensor_data:
            df_sensors = load_sensor_data(str(SENSOR_DATA_PATH))
            # normalize column names if needed
            df_sensors.columns = [c.lower() for c in df_sensors.columns]
        else:
            df_sensors = pd.read_csv(str(SENSOR_DATA_PATH))
            df_sensors.columns = [c.lower() for c in df_sensors.columns]
        df_sensors["sensor_score"] = df_sensors.apply(compute_sensor_score_row, axis=1)

        if generate_sensor_alerts:
            sensor_alerts = generate_sensor_alerts(df_sensors)
        else:
            # fallback alerts
            mx = float(df_sensors["sensor_score"].max()) if not df_sensors.empty else 0.0
            if mx >= 0.75:
                sensor_alerts = [f"Critical sensor escalation detected (score={mx:.2f})"]
            elif mx >= 0.55:
                sensor_alerts = [f"Moderate sensor escalation detected (score={mx:.2f})"]
            else:
                sensor_alerts = ["No significant sensor escalation detected."]
    except Exception as e:
        df_sensors = pd.DataFrame()
        sensor_alerts = [f"Sensor load failed: {e}"]
else:
    sensor_alerts = [T["no_sensors"]]

# ============================================================
# TABS
# ============================================================
tab_map, tab_summary, tab_state, tab_scenario ,  tab_compare = st.tabs(T["tabs"])

# ============================================================
# TAB: MAP
# ============================================================
with tab_map:

    st.markdown("""
    <div class="status-card">
    <b>Concept:</b> This map represents the spatial distribution of wildfire risk derived from
    climate-driven AI models. Each cell is an independent risk estimation unit, forming the
    baseline layer of the NEXUS decision system.
    </div>
    """, unsafe_allow_html=True)

    section(T["map_title"])

    st.markdown("<div class='status-card'>", unsafe_allow_html=True)

    if render_point_risk_map and render_hex_risk_map:
        if map_mode == "Hex" and len(df_day) >= 300:
            render_hex_risk_map(df_day, selected_date)
        else:
            render_point_risk_map(df_day, selected_date)
    else:
        lat_col = next((c for c in df_day.columns if c.lower() in ["lat", "latitude"]), None)
        lon_col = next((c for c in df_day.columns if c.lower() in ["lon", "long", "longitude"]), None)

        if lat_col and lon_col and not df_day.empty:
            tmp = df_day.rename(columns={lat_col: "lat", lon_col: "lon"}).copy()
            tmp = tmp[["lat", "lon", "risk_score"]].dropna()
            st.map(tmp, zoom=6)
            st.caption("Fallback map (components/maps.py not connected yet).")
        else:
            st.warning("Map unavailable: missing lat/lon columns or empty dataset.")

    st.markdown("</div>", unsafe_allow_html=True)

    st.markdown(f"#### {T['legend']}")
    st.markdown("""
    <div class="legend-box">
        <span style="color:#16A34A">â—</span> Low â€” score &lt; 0.30<br>
        <span style="color:#FACC15">â—</span> Medium â€” 0.30 â€“ 0.60<br>
        <span style="color:#EF4444">â—</span> High â€” 0.60 â€“ 0.80<br>
        <span style="color:#7C3AED">â—</span> Extreme â€” &gt; 0.80
    </div>
    """, unsafe_allow_html=True)

# ============================================================
# ============================================================
# TAB: DECISION SUMMARY (FINAL â€“ CLEAN + STABLE)
# ============================================================
with tab_summary:

    section(T["decision_title"])

    st.markdown("""
    <div class="status-card">
    <b>Decision Layer Concept:</b>
    This layer fuses climate risk with ground-truth sensor confirmation
    to produce a single explainable operational decision.
    </div>
    """, unsafe_allow_html=True)

    # -----------------------------
    # FUSION SCORE
    # -----------------------------
    climate_raw = float(df_day["risk_score"].mean()) if not df_day.empty else 0.0
    climate_score = float(np.clip(climate_raw, 0, 1))
    sensor_score = float(df_sensors["sensor_score"].max()) if not df_sensors.empty else None

    fusion = compute_fusion_score(climate_score, sensor_score) if compute_fusion_score else simple_fusion_score(climate_score, sensor_score)
    level = fusion_level(fusion) if fusion_level else simple_fusion_level(fusion)

    st.markdown("<div class='status-card'>", unsafe_allow_html=True)
    c1, c2, c3 = st.columns(3)
    c1.metric("Climate Score", round(climate_score, 2))
    c2.metric("Sensor Score", "-" if sensor_score is None else round(sensor_score, 2))
    c3.metric("Fusion Score", round(fusion, 2))
    st.markdown(f"### ğŸ”¥ FINAL LEVEL: **{level}**")
    st.markdown("</div>", unsafe_allow_html=True)

    # ============================================================
    # SENSOR MAP (GUARANTEED TO SHOW)
    # ============================================================
    section(T["sensor_map_title"])
    st.caption(T["sensor_map_caption"])
    st.markdown("<div class='status-card'>", unsafe_allow_html=True)

    if df_sensors.empty:
        st.warning("No sensor data available.")
        df_map = pd.DataFrame()
    else:
        df_map = df_sensors.copy()

        lat_col = next((c for c in df_map.columns if c.lower() in ["lat", "latitude"]), None)
        lon_col = next((c for c in df_map.columns if c.lower() in ["lon", "longitude", "long"]), None)

        if not lat_col or not lon_col:
            st.error(f"Sensor data missing lat/lon columns. Found: {list(df_map.columns)}")
            df_map = pd.DataFrame()
        else:
            df_map = df_map.rename(columns={lat_col: "lat", lon_col: "lon"})
            df_map["lat"] = pd.to_numeric(df_map["lat"], errors="coerce")
            df_map["lon"] = pd.to_numeric(df_map["lon"], errors="coerce")
            df_map = df_map.dropna(subset=["lat", "lon"])

            if df_map.empty:
                st.error("All sensor locations are invalid.")
            else:
                st.map(df_map[["lat", "lon"]], zoom=7)

                if render_sensor_nodes_map:
                    with st.expander("Enhanced sensor visualization"):
                        render_sensor_nodes_map(df_map)

                cols = [c for c in ["device_id", "sensor_score", "pm25", "temp_c", "rh", "battery_v", "rssi"] if c in df_map.columns]
                if cols:
                    st.dataframe(df_map[cols].reset_index(drop=True), use_container_width=True)

    st.markdown("</div>", unsafe_allow_html=True)

    # ============================================================
    # FORECAST
    # ============================================================
    section(T["forecast_title"])
    st.markdown("<div class='status-card'>", unsafe_allow_html=True)

    df_hist = df.copy()
    df_hist["d"] = df_hist[date_col].dt.date
    hist = df_hist.groupby("d")["risk_score"].mean().tail(7)

    if len(hist) > 1:
        st.line_chart(hist)
    else:
        st.info(T["trend_empty"])

    st.markdown("</div>", unsafe_allow_html=True)

    # ============================================================
    # PROXIMITY
    # ============================================================
    section(T["proximity_title"])
    st.markdown("<div class='status-card'>", unsafe_allow_html=True)

    if not df_map.empty:
        ref_lat = df_map["lat"].mean()
        ref_lon = df_map["lon"].mean()
    else:
        ref_lat = ref_lon = None

    if ref_lat is None:
        st.info("No reference point available.")
    else:
        stations = pd.DataFrame([
            {"station": "Feuerwehr KÃ¶ln", "lat": 50.9375, "lon": 6.9603},
            {"station": "Feuerwehr Bonn", "lat": 50.7374, "lon": 7.0982},
            {"station": "Feuerwehr DÃ¼sseldorf", "lat": 51.2277, "lon": 6.7735},
        ])

        stations["dist_km"] = stations.apply(lambda r: haversine_km(ref_lat, ref_lon, r["lat"], r["lon"]), axis=1)
        nearest = stations.sort_values("dist_km").iloc[0]

        c1, c2, c3 = st.columns(3)
        c1.metric("Nearest Station", nearest["station"])
        c2.metric("Distance", f"{nearest['dist_km']:.1f} km")
        c3.metric("ETA", f"{int(nearest['dist_km']/45*60)} min")

    st.markdown("</div>", unsafe_allow_html=True)

    # ============================================================
    # ALERTS
    # ============================================================
    section(T["alerts_title"])
    st.markdown("<div class='status-card'>", unsafe_allow_html=True)

    alerts = []
    alerts.extend(state_alerts)
    alerts.extend(sensor_alerts)

    if fusion >= 0.8:
        alerts.insert(0, "ğŸ”´ Critical fusion escalation")
    elif fusion >= 0.6:
        alerts.insert(0, "ğŸŸ  Elevated fusion escalation")
    else:
        alerts.insert(0, "ğŸŸ¢ Normal conditions")

    for a in alerts[:10]:
        st.info(a)

    st.markdown("</div>", unsafe_allow_html=True)

    # ============================================================
    # AUTO EXPLANATION
    # ============================================================
    section(T["auto_explain"])
    st.markdown("<div class='status-card'>", unsafe_allow_html=True)

    if generate_risk_explanation:
        st.markdown(generate_risk_explanation(selected_date, states_trend, None, alerts))
    else:
        st.markdown("- Decision is based on climate + sensor fusion.")

    st.markdown("</div>", unsafe_allow_html=True)

# ============================================================
# TAB: STATES
# ============================================================
with tab_state:
    section(T["state_title"])
    st.markdown("<div class='status-card'>", unsafe_allow_html=True)

    if states_trend is None:
        st.warning("No state trend available.")
    else:
        if render_state_risk_map:
            render_state_risk_map(states_trend)
        st.dataframe(states_trend.drop(columns=["geometry"], errors="ignore"), use_container_width=True)

    st.markdown("</div>", unsafe_allow_html=True)

# ============================================================
# TAB: SCENARIO
# ============================================================
with tab_scenario:
    section(T["scenario_title"])
    st.markdown("<div class='status-card'>", unsafe_allow_html=True)
    st.markdown(T["scenario_text"])

    if render_scenario_simulator:
        render_scenario_simulator()
    else:
        base = float(np.clip(climate_raw, 0, 1))
        delta = st.slider("Î” climate risk", -0.3, 0.3, 0.0, 0.01)
        if st.button(T["run_scenario"]):
            st.session_state["scenario_risk_score"] = float(np.clip(base + delta, 0, 1))
            st.success("Scenario updated.")
            st.rerun()

    st.markdown("</div>", unsafe_allow_html=True)

# ============================================================
# TAB: COMPARE
# ============================================================
with tab_compare:
    section("âš–ï¸ Real Risk vs Scenario Comparison")

    scenario_risk = st.session_state.get("scenario_risk_score", None)
    if scenario_risk is None:
        st.warning(T["compare_hint"])
    else:
        st.markdown("<div class='status-card'>", unsafe_allow_html=True)

        if render_compare_map:
            scenario_df = df_day.copy()
            scenario_df["risk"] = scenario_risk
            delta_df = render_compare_map(df_day, scenario_df)

            c1, c2, c3 = st.columns(3)
            c1.metric("Mean Î” Risk", round(delta_df["delta"].mean(), 2))
            c2.metric("Max Increase", round(delta_df["delta"].max(), 2))
            c3.metric("Max Decrease", round(delta_df["delta"].min(), 2))
        else:
            delta = scenario_risk - climate_score
            st.metric("Scenario Î”", f"{delta:+.2f}")

        st.markdown("</div>", unsafe_allow_html=True)

# ============================================================
# FOOTER
# ============================================================
st.divider()
st.caption("Â© 2026 NEXUS AI Systems | AI Decision Engine")


            
